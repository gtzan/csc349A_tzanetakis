\documentclass[12pt]{beamer}
\usepackage{xcolor}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{algorithm,algorithmic}
\usepackage{amsmath}
\usetheme{Air}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\DeclareMathOperator*{\argmax}{arg\,max}

\title[CSC349A Numerical Analysis]{CSC349A Numerical Analysis}


\logo{\pgfputat{\pgfxy(-0.5,7.5)}{\pgfbox[center,base]{\includegraphics[width=1.0cm]{figures/uvic}}}}  
\beamertemplatenavigationsymbolsempty

    \defbeamertemplate{footline}{author and page number}{%
      \usebeamercolor[fg]{page number in head/foot}%
      \usebeamerfont{page number in head/foot}%
      \hspace{1em}\insertshortauthor\hfill%
      \insertpagenumber\,/\,\insertpresentationendpage\kern1em\vskip2pt%
    }
    \setbeamertemplate{footline}[author and page number]{}



\subtitle[Lecture 13]{Lecture 13}
\date[2023]{2023}
\author[R. Little]{Rich Little}
\institute[University of Victoria]{University of Victoria}
%\logo{\includegraphics[scale=.25]{unilogo.pdf}}
\begin{document}
\frame{\maketitle} % <-- generate frame with title


\AtBeginSection[]
{
\begin{frame}<beamer>[allowframebreaks]{Table of Contents}
\tableofcontents[currentsection,currentsubsection, 
    hideothersubsections, 
    sectionstyle=show/shaded,
]
\end{frame}
}

\section{Midterm Logistics}

\begin{frame}{Midterm Logistics}
\begin{itemize} 

\item The midterm is on Thursday, November 9 and is 60 minutes long 

\item The exam is closed book (see below regarding formula sheet)

\item Only simple, scientific calculators (the ones you use for math classes) are allowed. If you bring anything programmable or with a large screen and or internet access you will not be allowed to use it.

\item You can bring a single letter size (8.5 by 11) piece of paper with formulas and notes (it can be double sided)
\end{itemize} 

\end{frame} 


\begin{frame}{Midterm Material} 
\begin{itemize}

\item{The material covered corresponds to the end of chapter 4 to chapter 7 and the beginning of chapter 9.}
\item{That is lectures 7 to 12 and Handouts 6 to 15.} 
\item{In terms of topics these are condition, and stability (part 1).}
\item{Roots of equations (Bisection, Newton and Secant) and rates of convergence, Horner's method (part 2).} 
\item{Naive Gaussian Elimination (part 3).} 
\item{In addition you should study all the assignments
you have completed and the corresponding problems from the sample exam
questions.}

\end{itemize}

{\bf Note:} There is no MATLAB on the exam.

\end{frame} 

\section{Gaussian Elimination with Partial Pivoting}

\begin{frame}{Gaussian Elimination with Partial Pivoting}

\begin{itemize}

\item{The Naive Gaussian elimination algorithm will fail if any of the pivots $a_{11}, a_{22}^{(1)},a_{33}^{(2)}, ...$ is equal to $0$.}
\item{Mathematically, it works provided this does not occur.}
\item{Algorithmically, it breaks down when the pivots are even close to $0$ because of floating-point arithmetic.}
\item{The problem occurs in the multiplier, it becomes far larger than the other entries.}
\end{itemize}

\end{frame}

\begin{frame}{Example 1}
Solve the $n=2$ linear system with the following augmented matrix using $k=4$, $b=10$, rounding, floating-point arithmetic.
\[
\begin{bmatrix}[cc|c]
	0.003	&	59.14	&	59.17 \\
	5.291		&	-6.13	&	46.78
\end{bmatrix}
\]
\vspace{2 in}
\end{frame}

\begin{frame}{Example 1 continued}

\end{frame}

\begin{frame}{Analysis of the above Example}

\begin{itemize}

\item{The source of the extremely inaccurate computed solution $\hat{x}$ is the {\bf large magnitude of the multiplier}.}
\item{Here, 1764 is much larger than the rest of the numbers in the system.}
\item{This number is large because the pivot, $a_{11}=0.003$, is much smaller than the other numbers in the system.}
\item{Consequently, in the floating-point computations of $a_{22}^{(1)}$ and $b_2^{(1)}$, the numbers $-6.13$ and $46.78$ are so small they are lost.}
\item{The {\bf partial pivoting strategy} is designed to avoid the selection of small pivots.}
\end{itemize}

\end{frame}

\begin{frame}{Partial Pivoting}

\begin{itemize}

\item{At step $k$ of forward elimination, where $1 \leq k \leq n-1$, choose the pivot to be the {\bf largest entry in absolute value}, from
\[
\begin{bmatrix}
	a_{kk} \\
	a_{k+1,k} \\
	a_{k+2,k} \\
	\vdots \\
	a_{n,k}
\end{bmatrix}
\]
}
\item{If $a_{pk}$ is the largest (that is, $|a_{pk}|=\max_{k \leq i \leq n}|a_{ik}|$), then switch row $k$ with row $p$. }
\item{Note that $|mult| \leq 1$ for all multipliers since the denominator is always the largest value.}
\item{Note also that switching rows does not change the final solution. It is an elementary row operation of type 3.}
\end{itemize}

\end{frame}

\begin{frame}{Partial Pivoting Pseudocode}
\begin{algorithm}[H]
\begin{algorithmic}[1]
\FOR{$k=1$ to $n-1$}
\STATE $p = k$
\FOR{$i=k+1$ to $n$}
\STATE Find largest pivot
\ENDFOR
\IF {$p \neq k$}
\FOR{$j=k$ to $n$}
\STATE swap $a_{kj}$ and $a_{pj}$
\ENDFOR
\STATE swap $b_{k}$ and $b_{p}$
\ENDIF
\STATE do forward elimination
\ENDFOR
\STATE do back susbstitution
\end{algorithmic}
\caption{pseudocode for partial pivoting}
\label{alg:seq}
\end{algorithm}
\end{frame} 

\begin{frame}{Example 2 - Pivoting}
Solve the $n=2$ linear system with the following augmented matrix using $k=4$, $b=10$, rounding, floating-point arithmetic with partial pivoting.
\[
\begin{bmatrix}[cc|c]
	0.003	&	59.14	&	59.17 \\
	5.291		&	-6.13	&	46.78
\end{bmatrix}
\]
\vspace{2 in}

\end{frame}

\begin{frame}{Example 2 - Pivoting continued}


\end{frame}


\section{Gaussian Elimination with Scaling}

\begin{frame}{Scaling}

\begin{itemize}
\item{Section 9.4.3 on page 270 in the 8th edition of the text.}
\item{Nothing in the Handouts on this topic.}
\item{If the entries of maximum absolute value in different rows (equations) differ greatly, the computed solution (using floating point arithmetic and partial pivoting) can be very inaccurate.}
\end{itemize}

\end{frame}

\begin{frame}{Example 3 - Scaling}
Using $k=4$ precision, floating-point arithmetic with rounding, solve the following system by Gaussian Elimination with partial pivoting.
\[
\begin{bmatrix}[cc|c]
  2  &  100,000 & 100,000 \\
  1  &  1  &  2
\end{bmatrix}
\]
\vspace{2 in}

\end{frame}

\begin{frame}{Example 3 - Scaling continued}


\end{frame}

\begin{frame}{Scaling: Equilibration}

We look at two ways of using {\bf scaling} to solve this problem: (1) Equilibration and (2) Scaled Factors.

\vspace{\baselineskip}
{\bf (1) Equilibration:}
\begin{itemize}
\item{Multiply each row by a nonzero constant so that the \underline{largest} entry in each row of $A$ has magnitude of $1$.}
\item{Go through example again with scaling.}
\item{Problem with this form of scaling:}
\begin{itemize}
\item{Introduces another source of round-off error.}
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Scaling: Scaled Factors}

{\bf (2) Scaled Factors:}
\begin{itemize}
\item{Use the scaling factors to pick pivots but NOT actually scaling.}
\item{Let $s_i = \max_{1 \leq j \leq n} |a_{ij}|$ for $i=1,2,\dots, n$.}
\item{Step $k=1$: pivot is max of

\[
\begin{bmatrix}
  |a_{11}/s_1| \\
  |a_{21}/s_2| \\
  \vdots \\
  |a_{n1}/s_n| 
\end{bmatrix}
\]

If $|a_{p1}/s_p|$ is the max then interchange rows $1$ and $p$ then do forward elimination step.}

\end{itemize}
\end{frame}

\begin{frame}{Scaling: Scaled Factors II}

\begin{itemize}
\item{Step $k=2$: pivot is max of

\[
\begin{bmatrix}
  |a_{22}^{(1)}/s_2| \\
  |a_{32}^{(1)}/s_3| \\
  \vdots \\
  |a_{n2}^{(1)}/s_n| 
\end{bmatrix}
\]

If $|a_{q2}/s_q|$ is the max then interchange rows $2$ and $q$ then do forward elimination step.}
\item{etc.}
\item{Finish with back susbstitution as usual.}
\end{itemize}

\end{frame}


\begin{frame}{Example 4 - Scaled Factors}
Using $k=4$ precision, floating-point arithmetic with rounding, solve the following system by Gaussian Elimination with partial pivoting and scaling.
\[
\begin{bmatrix}[cc|c]
  2  &  100,000 & 100,000 \\
  1  &  1  &  2
\end{bmatrix}
\]
\vspace{2 in}

\end{frame}

\begin{frame}{Example 4 - continued}


\end{frame}

\section{Determinant of $A$}

\begin{frame}{Determinant of $A$}

The reduction of $A$ to upper triangular form by {\bf Naive Gaussian elimination} uses only the type 2 elementary row operation
\[ E_i = E_i - factor \times E_j. \]
This row operation does not change the value of the determinant of $A$.
That is, if no rows are interchanged then,
\[ \det A = a_{11}a_{22}^{(1)}a_{33}^{(2)} \dotsm a_{nn}^{(n-1)} \]
since the determinant of a triangular matrix is equal to the product of its diagonal entries.

\end{frame}

\begin{frame}{Determinant of $A$ II}

However, if {\bf Gaussian elimination with partial pivoting} is used, then each row interchange causes the determinant to change signs 
(that is, determinant is multiplied by $-1$.)

Thus, if $m$ row interchanges are done during the reduction of $A$ to upper triangular form, then
\[ \det A = (-1)^m a_{11}a_{22}^{(1)}a_{33}^{(2)} \dotsm a_{nn}^{(n-1)} \]

As a consequence, Gaussian elimination provides us with a simple method of calculating the determinant of a matrix.

\end{frame}

\section{Stability and Condition of Systems of Linear Equations}

\begin{frame}{Stability of Algorithms for Solving $Ax=b$}

\begin{itemize}
\item{Given a nonsingular matrix $A$, a vector $b$ and some algorithm for computing the solution of $Ax=b$,  let $\hat{x}$  
denote the computed solution using this algorithm.}
\item{The computation is said to be stable if there exist small perturbations $E$ and $e$ of $A$ and $b$, respectively, such that $\hat{x}$
 is close to the exact solution $y$ of the perturbed linear system

\[ (A+E)y=b+e \]}

\item{That is, the computed solution $\hat{x}$ is very close to the exact solution of some small perturbation of the given problem.}
\end{itemize}
\end{frame}

\begin{frame}{Known Results}

\begin{itemize}
\item{Gaussian elimination without pivoting may be unstable.}
\item{In practice, Gaussian elimination with partial pivoting is almost always stable.}
\item{A much more stable version of Gaussian elimination uses complete pivoting, which uses both row and column interchanges.}
\item{However, as this algorithm is much more expensive to implement and since partial pivoting is almost always stable, complete pivoting is seldom used.}
\end{itemize}
\end{frame}

\begin{frame}{Condition of $Ax=b$}

\begin{itemize}
\item{A given problem $Ax=b$ is ill-conditioned if its exact solution is very sensitive to small changes in the data $[A | b]$.}
\item{That is, if there exist small perturbations $E$ and $e$ of $A$ and $b$, respectively, such that $x=A^{-1}b$
 is not close to the exact solution $y$ of the perturbed linear system

\[ (A+E)y=b+e, \]

then the linear system $Ax=b$ is ill-conditioned.}
\item{If such perturbations $E$ and $e$ do not exist, then $Ax=b$ is well conditioned.}
\item{{\bf Example:} $n \times n$ Hilbert matrices are ill-conditioned.}
\end{itemize}
\end{frame}

\begin{frame}{Example 2 - Condition of a linear system}
Recall, the linear system $Hx=b$, with $H=\begin{bmatrix} 1 &	1/2 & 1/3 \\ 1/2	 & 1/3 & 1/4 \\ 1/3 & 1/4 & 1/5 \end{bmatrix}$, $b=\begin{bmatrix} 11/6 \\ 13/12 \\ 47/60 \end{bmatrix}$ and solution $x=\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}$, is ill-conditioned. 

We do this by perturbing $H$ and $b$ as follows. Let $(H+E)=\begin{bmatrix} 1 &	1/2 & 0.333 \\ 1/2	 & 0.333 & 1/4 \\ 0.333 & 1/4 & 1/5 \end{bmatrix}$, $(b+e)=\begin{bmatrix} 1.83 \\ 1.08 \\ 0.783 \end{bmatrix}$, and solving to get $y=\begin{bmatrix} 1.0895... \\ 0.48796... \\ 1.4910.... \end{bmatrix}$

\vspace{3 in}
\end{frame} 

\begin{frame}{Matrix Norms}

\begin{itemize}

\item{The {\it norm} of a matrix (or vector) is a measure of the "size" of the matrix.}
\item{We denote the norm of a matrix $A$ by $\|A\|$.}
\item{There exist a number of different ways of calculating a norm.}
\begin{itemize}
\item{$\|A\|_e=\sqrt{\sum_i{\sum_j{a_{ij}^2}}}$ is the Euclidean norm.}
\item{$\|A\|_{\inf}=\max_i{\sum_j{|a_{ij}|}}$ is the uniform norm, etc.}
\end{itemize}
\item{Turns out, for any of these forms of the norm, when solving for $Ax=b$,
\[
\frac{\|x-y\|}{\|x\|} \leq \|A\|\|A^{-1}\|\frac{\|e\|}{\|b\|}
\]}
\end{itemize}
\end{frame}

\begin{frame}{Matrix Condition Number}

\begin{itemize}

\item{The condition number of a matrix, $A$, is given by 
\[cond[A]= \|A\|\|A^{-1}\|\]}
\item{Properties of the condition number.}
\begin{itemize}
\item{$cond[A] \geq 1$}
\item{$cond[I]=1$}
\end{itemize}
\item{As usual, the higher the condition number the more ill-conditioned it is, but the range of well-conditioned matrices is bigger.}
\item{For example, if consider $k=4$, $b=10$, floating-point, then a condition number between $1$ and $100$ is considered well-conditioned.}
\end{itemize}
\end{frame}

\begin{frame}{Example 3 - Condition Number}
Verify Example 2 using the condition number, with uniform norms.

\vspace{3 in}
\end{frame} 



\end{document} 




