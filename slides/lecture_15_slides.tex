\documentclass[12pt]{beamer}
\usepackage{xcolor}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{algorithm,algorithmic}
\usepackage{hyperref}
\usepackage{enumerate}
\usetheme{Air}

\DeclareMathOperator*{\argmax}{arg\,max}

\title[CSC349A Numerical Analysis]{CSC349A Numerical Analysis}


\logo{\pgfputat{\pgfxy(-0.5,7.5)}{\pgfbox[center,base]{\includegraphics[width=1.0cm]{figures/uvic}}}}  
\beamertemplatenavigationsymbolsempty

    \defbeamertemplate{footline}{author and page number}{%
      \usebeamercolor[fg]{page number in head/foot}%
      \usebeamerfont{page number in head/foot}%
      \hspace{1em}\insertshortauthor\hfill%
      \insertpagenumber\,/\,\insertpresentationendpage\kern1em\vskip2pt%
    }
    \setbeamertemplate{footline}[author and page number]{}



\subtitle[Lecture 15]{Lecture 15}
\date[2023]{2023}
\author[R. Little]{Rich Little}
\institute[University of Victoria]{University of Victoria}
%\logo{\includegraphics[scale=.25]{unilogo.pdf}}
\begin{document}
\frame{\maketitle} % <-- generate frame with title


\AtBeginSection[]
{
\begin{frame}<beamer>[allowframebreaks]{Table of Contents}
\tableofcontents[currentsection,currentsubsection, 
    hideothersubsections, 
    sectionstyle=show/shaded,
]
\end{frame}
}

\section{Barycentric Lagrange Interpolation}

\begin{frame}{Barycentric Lagrange Interpolation} 

Lagrange can suffer from round-off error instability due to the number of computations, but there is a form of Lagrange where we can reduce the number of computations significantly. Recall, given ${(x_i,f(x_i))}, 0 \leq i \leq n$, 
\begin{align*}
P(x) &= \sum_{i=0}^{n} L_i(x) f(x_i)
\end{align*}
where
\begin{align*}
L_i(x) &= \prod_{j=0,j \neq i}^{n} \frac{x-x_j}{x_i-x_j}, \;\;\; \mbox{for } i=0,1,2,\dots,n 
\end{align*}

\end{frame} 

\begin{frame}{Barycentric Lagrange Interpolation II} 
Note,
\begin{align*}
L_i(x) &= \prod_{j=0,j \neq i}^{n} \frac{x-x_j}{x_i-x_j} \\
&= \prod_{j=0,j \neq i}^{n} \frac{x-x_j}{x_i-x_j} \cdot \frac{x-x_i}{x-x_i} \\
&= \prod_{j=0}^{n} (x-x_j) \cdot \prod_{j=0,j \neq i}^{n} \frac{1}{x_i-x_j} \cdot \frac{1}{x-x_i} \\
&= \prod_{j=0}^{n} (x-x_j) \cdot \frac{1}{\prod_{j=0,j \neq i}^{n}(x_i-x_j)} \cdot \frac{1}{x-x_i}
\end{align*}
\end{frame} 

 
\begin{frame}{Barycentric Lagrange Interpolation III} 
Let $L(x)=\prod_{j=0}^{n} (x-x_j)$ and $w_i=\frac{1}{\prod_{j=0,j \neq i}^{n}(x_i-x_j)}$, for each $i=0,1,2,\dots,n$, then
\begin{align*}
L_i(x) &=L(x)\frac{w_i}{x-x_i}, \;\;\; \mbox{for } i=0,1,2,\dots,n
\end{align*}
and
\begin{align*}
P(x) &= L(x)\sum_{i=0}^{n} \frac{w_i}{x-x_i} f(x_i)
\end{align*}
Note, if $x=x_i$, then $P(x_i)=f(x_i)$ so there is no need to calculate. Just test for $x_i$ in computation.
\end{frame} 

\begin{frame}{Example 1}
Evaluate $\ln(2)$ using Lagrange polynomial interpolation, given that
\begin{align*}
\ln{1} &= 0 \\
\ln 4 &= 1.386294 \\
\ln 6 &= 1.791760
\end{align*}
\vspace{2 in}
\end{frame}

\begin{frame}{Example 1 continued}
\end{frame}

\section{Finding the coefficients of the interpolating polynomial} 

\begin{frame}{Finding the coefficients of the interpolating polynomial} 
Although the Langrange polynomial is well-suited to solving intermediate values it does not give you a polynomial in simple form
\[
P(x) = a_0 + a_1x + \dotsm + a_nx^n
\]

The coefficients of such an interpolating polynomial can be determined by solving a system of linear equations.

\end{frame} 

\begin{frame}{Finding the coefficients of the interpolating polynomial} 

Given a function $f(x)$ and distinct points $x_0, x_1, ..., x_n$, let $P(x)$ be the polynomial of degree $\leq n$ for which $P(x_i) = f(x_i)$ for $i=0,1,...,n$.

Then,
\begin{eqnarray*}
a_0 + a_1x_0 + \dotsb + a_nx_0^n &=& f(x_0) \\
a_0 + a_1x_1 + \dotsb + a_nx_1^n &=& f(x_1) \\
\vdots \\
a_0 + a_1x_n + \dotsb + a_nx_n^n &=& f(x_n)
\end{eqnarray*}
\end{frame} 

\begin{frame}{Finding the coefficients of the interpolating polynomial} 

In matrix form, solve

\[
\begin{bmatrix}
    1       & x_0 & \dots & x_0^n \\
   1       & x_1 & \dots & x_1^n \\
    \vdots & \vdots & \ddots & \vdots \\
   1       & x_n & \dots & x_n^n
\end{bmatrix}
\begin{bmatrix}
    a_0 \\
    a_1  \\
    \vdots \\
    a_n 
\end{bmatrix}
=
\begin{bmatrix}
   f(x_0) \\
  f(x_1)  \\
    \vdots \\
    f(x_n) 
\end{bmatrix}
\]

So, if $n=2$, we let $P(x) = a_0 + a_1x + a_2x^2$ and solve

\[
\begin{bmatrix}
    1       & x_0 &  x_0^2 \\
   1       & x_1 &  x_1^2 \\
   1       & x_2 &  x_2^2
\end{bmatrix}
\begin{bmatrix}
    a_0 \\
    a_1  \\
    a_2 
\end{bmatrix}
=
\begin{bmatrix}
   f(x_0) \\
  f(x_1)  \\
    f(x_2) 
\end{bmatrix}
\]
\end{frame} 

\begin{frame}{Example 2}
Let $f(x) = \sin x$, $x_0 = 0.2$, $x_1 = 0.5$, and $x_2 = 1$ and find the interpolating polynomial.
\vspace{3 in}
\end{frame}

\begin{frame}{Note} 

An interpolating polynomial can be specified in many different forms.
\begin{enumerate}
\item{For example the form 
can be $a(x-x_2)^2 + b(x-x_2) + c$ or}
\item{using the Lagrange form for $n=2$: 
\begin{align*}
P(x) &= L_0(x) f(x_0) + L_1(x) f(x_1) + L_2(x) f(x_2) \\
     &= \frac{(x-x_1)(x-x_2)}{(x_0 - x_1)(x_0-x_2)}f(x_0) + \frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)} f(x_1) \\ 
     &+ \frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}f(x_2) 
\end{align*} 
\noindent 
or}
\item{simply as $P(x) = Ax^2 + Bx + C$.}
\end{enumerate}

We will show that all of these forms are identical as the interpolating polynomial is unique.  
\end{frame} 

\section{Uniqueness of the Interpolating Polynomial}

\begin{frame}{Uniqueness} 

{\bf Theorem:} Given any $n+1$ distinct points $x_0, x_1, \dots, x_n$ and any $n+1$ values 
$f(x_0), f(x_1), \dots, f(x_n)$, there exists a unique polynomial $P(x)$ of degree $\leq n$ such that 
\[
P(x_i) = f(x_i) \mbox{ for } i = 0, 1, ..., n
\]
\noindent 
{\bf Proof:} \\
{\it Existence:} by construction of the Lagrange interpolating polynomial 
\\
\end{frame} 

\begin{frame}{Uniqueness proof} 

\end{frame} 


\section{The Runge Phenomenon}

\begin{frame}{Error term of polynomial interpolation} 
\noindent 
{\bf Theorem:} \\ 
Let $x_0, x_1, \dots x_n$ be any distinct points in $[a,b]$. Let $f(x) \in C^{n+1} [a,b]$ and let 
$P(x)$ interpolate $f(x)$ at ${x_i}$. 

Then for each $\hat x \in [a,b]$, there exists a value $\xi$ in $(a,b)$ such that 
\[
f(\hat x) = P(\hat x) + \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{i=0}^{n} (\hat x - x_i)
\]
for example for $n=3$ 
\[
f(\hat x) = P(\hat x) + \frac{f^{(4)}(\xi)}{24} (\hat x - x_0)(\hat x - x_1)(\hat x - x_2)(\hat x - x_3)
\]

\noindent 
The limitation of this error bound for polynomial interpolation is the need to find an upper bound for 
$f^{(n+1)}(x)$ on $[a,b]$. 
\end{frame} 

\begin{frame}{The Runge Phenomenon}

The following example is the classical example to illustrate the oscillatory nature and thus the unsuitability of high order interpolating polynomials.

{\bf Example:} Consider the problem of interpolating

\[
f(x)= \frac{1}{1+25x^2}
\]

\noindent
on the interval $[-1,1]$ at $n+1$ equally-spaced points $x_i$ by the interpolating polynomial $P_n(x)$.

\end{frame}

\begin{frame}{Graphs of $f(x)$, $P_5(x)$, and $P_{20}(x)$}
\begin{figure} 
  \centering
  \includegraphics[scale=0.6]{runge}
  \caption{The Runge function}
  \label{fig:runge}
\end{figure}


\end{frame} 

\begin{frame}{Runge's Theorem}
\begin{itemize}
\item{Runge proved that as $n \rightarrow \infty$, $P_n(x)$ diverges from $f(x)$ for all values of $x$ such that $0.726 \leq |x| < 1$ (except for the points of interpolation $x_i$).}
\item{The interpolating polynomials do approximate $f(x)$ well for $|x|<0.726$.}
\item{One way to see that the difference between $f(x)$ and $P_n(x)$ becomes arbitrarily large as $n$ becomes large is to consider the error term for polynomial interpolation
\[
f(x)-P_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{i=0}^{n} (x - x_i)
\]
\noindent
As $n \rightarrow \infty$, it can be shown that $f(x)-P_n(x) \rightarrow \infty$ (at some points $x$ in $[-1,1]$).}
\end{itemize}
\end{frame}


\end{document} 



