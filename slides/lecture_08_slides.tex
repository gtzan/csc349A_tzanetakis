\documentclass[12pt]{beamer}
\usepackage{xcolor}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usetheme{Air}

\DeclareMathOperator*{\argmax}{arg\,max}

\title[CSC349A Numerical Analysis]{CSC349A Numerical Analysis}


\logo{\pgfputat{\pgfxy(-0.5,7.5)}{\pgfbox[center,base]{\includegraphics[width=1.0cm]{figures/uvic}}}}  
\beamertemplatenavigationsymbolsempty

    \defbeamertemplate{footline}{author and page number}{%
      \usebeamercolor[fg]{page number in head/foot}%
      \usebeamerfont{page number in head/foot}%
      \hspace{1em}\insertshortauthor\hfill%
      \insertpagenumber\,/\,\insertpresentationendpage\kern1em\vskip2pt%
    }
    \setbeamertemplate{footline}[author and page number]{}



\subtitle[Lecture 8]{Lecture 8}
\date[2023]{2023}
\author[R. Little]{Rich Little}
\institute[University of Victoria]{University of Victoria}
%\logo{\includegraphics[scale=.25]{unilogo.pdf}}
\begin{document}
\frame{\maketitle} % <-- generate frame with title


\AtBeginSection[]
{
\begin{frame}<beamer>[allowframebreaks]{Table of Contents}
\tableofcontents[currentsection,currentsubsection, 
    hideothersubsections, 
    sectionstyle=show/shaded,
]
\end{frame}
}


\section{Introduction and motivation for root finding} 

\begin{frame}{Roots or Zeros} 
\begin{definition} 
If we have an
equation with one variable: $f(x) = 0$ then a value $\hat x$ for
which this equation holds is called a {\it root} of the equation or
a {\it zero} of the function $f(x)$.
\end{definition} 
\end{frame} 

\begin{frame}{Families of functions for root finding}  
There are two main families which we will consider. 

\begin{itemize}
\item{Polynomials such as $f(x) = x^3 + x^2 +x + 1$ which are a special case will be treated
separately. For polynomials we will find both real and complex
roots.} 
\item{More general, non-polynomial algebraic functions and the so called transcedental functions, 
such as $f(x) = e^{-x} -x = 0$ will be what we will cover first and we will focus on
finding one or more real roots.} 
\item{Although in some cases it is possible
to derive the {\it root} analytically, in many cases this is
impossible in which case our only option is to use numerical methods.}
\end{itemize}
\end{frame} 

\begin{frame}{Usage of root finding} 
In practical engineering problems, frequently there are cases where we 
can not rearrange an equation so that the unknown quantity is on one
side of the equation and all the known quantities are on the other
side.  For example consider the equation describing the free fall of
the parachutist that we used to motivate numerical methods: 

\begin{equation} 
v(t) = \frac{gm}{c} (1-e^{-ct/m}) 
\end{equation}


\noindent 
Suppose that instead of being given $m,c,t$ and computing $v$, you
want to know the value of $c$ (drag coefficient) for a parchutist of
mass $m$ to attain a certain velocity after falling for time $t$. 
\end{frame}

\begin{frame}{Formulating as root finding}
It
is impossible to rearrange this equation so that $c$ is on one side 
and all the known quantities are on the other. However it is trivial 
to express it as follows: 

\begin{equation} 
\frac{gm}{c} (1-e^{-ct/m}) - v = 0 
\end{equation} 

\noindent 
where g,m,t,v are known. Now the task is to find the value of $c$ that 
makes this equation equal to $0$ i.e solve $f(c) = 0$. In this case
there is no analytic solution and we have to use numerical root
finding methods such as the ones we will cover in this course. 
\end{frame} 

\begin{frame}{Numerical iteration} 
All numerical methods are iterative i.e given one or more initial
approximations to a root $x_t$ they compute a sequence of
approximations. 
\begin{equation} 
lim_{i \rightarrow \infty} x_{i} = x_{t} 
\end{equation} 

In the 1830s it was proved that there are no finite algorithms
involving $+,-,*,/$ for computing the roots of polynomials
of degree $n$ if $n \geq 5$. 
\end{frame} 

\section{The Bisection method} 

\begin{frame}{Bisection and bracketing}
The {\bf Bisection} method can be used to compute a zero of any function $f(x)$ that is continuous on an interval $[x_l, x_u]$ for which $f(x_l) \times f(x_u) <0$.  

Consider $x_l$ and $x_u$ as {\it two initial approximations} to a zero, say $x_t$, of $f(x)$. The new approximation is the midpoint of the interval $[x_l, x_u]$ which is $x_r = \frac{x_l+x_u}{2}$.  
\vspace{2 in}
\end{frame}

\begin{frame}{The algorithm}
\begin{itemize}
\item If $f(x_r) = 0$, the $x_r$ is the desired zero of $f(x)$. Otherwise, a new interval $[x_l, x_u]$ that is half the length of the previous interval is determined as follows. 

\item If $f(x_l) \times f(x_r)<0$ then $[x_l, x_r]$ contains a zero, so set $x_u \leftarrow x_r$. Otherwise $f(x_u) \times f(x_r) < 0$ (necessarily) and $[x_r, x_u]$ contains a zero, so set $x_l \leftarrow x_r$. 
\end{itemize}

The above procedure is repeated, continually halving the interval $[x_l, x_u]$, until 
$[x_l, x_u]$ is sufficiently small, at which time the midpoint $x_r = \frac{x_l+x_u}{2}$ will be arbitrarily close to a zero of $f(x)$. 
\vspace{1 in}
\end{frame}

\begin{frame}{Iterarions $n$ for desired accuracy} 

Suppose you want the {\em absolute error} $< \varepsilon$, and that the length of the initial interval $[x_l, x_u]$ is $\Delta x^0$. 


\begin{table}[h]
\begin{center}
\begin{tabular}{c|c}
approximation & absolute error \\
\hline
$x_1 = \frac{x_l+x_u}{2}$ & $|x_t-x_1| \leq \frac{\Delta x^0}{2}$ \\ 
$x_2$                      & $|x_t-x_2| \leq \frac{\Delta x^0}{4}$ \\ 
$x_3$                      & $|x_t-x_3| \leq \frac{\Delta x^0}{8}$ \\ 
$\dots$                    & $\dots$ \\ 
$x_n$                      & $|x_t-x_n| \leq \frac{\Delta x^0}{2^n}$ \\ 

\end{tabular}
\caption{Relation of approximation and absolute error} 
\end{center}
\end{table}
\end{frame} 

\begin{frame}{Relating $n$ and $\varepsilon$} 
Therefore $\frac{\Delta x^0}{2^n} < \varepsilon$ implies that 
$2^n > \frac{\Delta x^0}{\varepsilon}$ and $n > log_2\left( \frac{\Delta x^0}{\varepsilon}{}\right)$

\vspace{\baselineskip}
 or 

\[
n \ln 2 > \ln{(\Delta x^0)} - \ln(\varepsilon) \;\; \mbox{and} \;\;\; n > \frac{\ln{(\Delta x^0)}-\ln{(\varepsilon)}}{\ln 2}
\] 
\end{frame} 

\begin{frame}{Example 1}
\noindent
Find the positive root of $f(x)=x^2-3$ such that $|E_t|<0.01$. Note that the true root is $x_t=\sqrt{3} \approx 1.73205$ so we will start with $x_l=1$ and $x_u=2$.
\vspace{3 in}
\end{frame}

\begin{frame}{Example 1 continued}

\end{frame}

\begin{frame}{Convergence Criterion} 

As this is an iterative algorithm that computes a sequence of approximations: 

\[
x_0, x_1, x_2, \dots, x_{i-1}, x_i, \dots 
\] 
\noindent 
to a zero $x_t$, recall that we can use the iterative approximation relative 
error: 
\[
|\varepsilon_{a}| =  \left| \frac{x_i - x_{i-1}}{x_i}\right| = \left | 1 - \frac{x_{i-1}}{x_i} \right| 
\]
\noindent 
is a good approximation to the actual relative $|\varepsilon_t|$ in $x_i$, and can be used to determine the accuracy of $x_i$. 
\end{frame} 

\begin{frame}{Approximation error}
Note that each approximation $x_i$ is equal to $\frac{x_u + x_l}{2}$, and the previous approximation is either $x_l$ or $x_u$. Therefore: 
\[
|x_i - x_{i-1}| =\left|\frac{x_l+x_u}{2}-\frac{2x_l}{2}\right|= \left|\frac{x_u - x_l}{2} \right|
\] 
\noindent thus 
\[
|\varepsilon_a| = \frac{|x_i-x_{i-1}|}{|x_i|} =\frac{\left|\frac{x_u-x_l}{2}\right|}{\left| \frac{x_u + x_l}{2} \right|} = \left|\frac{x_u - x_l}{x_u + x_l}\right|
\] 
\end{frame} 


\begin{frame}{Functions as arguments and global variables} 

\begin{itemize}
\item{Numerical methods frequently are expressed as iterations that require
you to evaluate a function (and sometimes its derivatives) for multiple
points.} 
\item{Examples include Euler's method which requires the evaluation
of the slope in the incremental update and the bisection method that
requires the evaluation of the function at the boundaries and midpoint
of the interval under consideration in each iteration}
\item{From a programming perspective in all these
cases we would like to abstract the numerical algorithm (Euler's
method, Bisection, Newton/Raphson) from the specific function being
evaluated.}
\item{In the same way that we can generalize a function by adding
a parameter or argument we would like to generalize our methods to
arbitrary functions.}
\end{itemize}
\end{frame}

\begin{frame}{Bisection example using MATLAB} 
The pseudocode algorithm for the Bisection method can be found in Handout 8. I have implemented it in MATLAB in order to 
solve problem 5.17 (page 143) of the textbook.

\vspace{\baselineskip}
{\bf Example}
The volume of liquid in a spherical tank is given by

\[
V = \frac{\pi h^2 (3R - h)}{3}
\]

where $h$ is the depth of the liquid and $R$ is the radius. If $R=3$, to what depth must the tank be filled so that it contains $V=30m^3$ of water?

\end{frame} 
\begin{frame}{Why Bisection?} 

{\bf Advantages}
\begin{itemize}
\item{If $f(x)$ is continuous and if appropriate initial values $x_l$ and $x_u$ can be found, then the method is {\bf guaranteed to converge}.}
\end{itemize}

{\bf Disadvantages}
\begin{itemize}
\item{converges slowly (requires more iterations than other methods)}
\item{it may be difficult to find appropriate initial values}
\item{it cannot be used to compute a zero $x_t$ of {\bf even multiplicity} of a function $f(x)$; that is, if}

\[
f(x)=(x-x_t)^mg(x)
\]

\noindent
where $m$ is a positive even integer and $g(x_t) \neq 0$


\end{itemize}

\end{frame} 
\end{document}

